{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b5fd2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/longshen/work/AccGen/AccGen')\n",
    "\n",
    "from evaluation.metrics import Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f9ff6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = Metric()\n",
    "import torch\n",
    "all_train_data_fp = '/data1/longshen/Datasets/Piano/POP909/latents/song_level_phr_seq_with_annot_and_instconf/train_data.pt'\n",
    "train_data = torch.load(all_train_data_fp)\n",
    "\n",
    "subset_size = 20\n",
    "train_data_list = list(train_data.items())[:subset_size]\n",
    "train_data_dict = dict(train_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdca9ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = [data['latent'] for data in train_data_dict.values()]\n",
    "n_phrases = [data['length'] for data in train_data_dict.values()]\n",
    "\n",
    "# pad to 512\n",
    "padded_latents = []\n",
    "for latent, n_phrase in zip(latents, n_phrases):\n",
    "    pad_size = 512 - n_phrase\n",
    "    padded_latent = torch.nn.functional.pad(latent, (0,0,0,pad_size), mode='constant', value=0)\n",
    "    padded_latents.append(padded_latent)\n",
    "padded_latents_tensor = torch.stack(padded_latents, dim=0)  # (B, 512, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c15e80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.242551729083061"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute_fid(padded_latents_tensor, n_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54854fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vae_inference import PhraseVAE\n",
    "vae = PhraseVAE().cuda()\n",
    "strs = vae.decode_batch(padded_latents_tensor.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24129649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from remi_z import MultiTrack\n",
    "mts = [MultiTrack.from_remiz_str(s) for s in strs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86d88be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_song_ids = list(train_data_dict.keys())\n",
    "for selected_id in selected_song_ids:\n",
    "    metric.mel_dict.pop(selected_id, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9db9d5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing memorization metrics: 100%|██████████| 20/20 [00:15<00:00,  1.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mem_rates': [0.3930635838150289,\n",
       "  0.4410134600158353,\n",
       "  0.37533512064343166,\n",
       "  0.31143232588699077,\n",
       "  0.3305993690851735,\n",
       "  0.40552416823603266,\n",
       "  0.41523178807947014,\n",
       "  0.4312865497076024,\n",
       "  0.40077569489334197,\n",
       "  0.4065484311050478,\n",
       "  0.3468819599109132,\n",
       "  0.4061032863849765,\n",
       "  0.4553759662684469,\n",
       "  0.3424845573095402,\n",
       "  0.42385057471264365,\n",
       "  0.4729064039408867,\n",
       "  0.9974293059125964,\n",
       "  0.4150298889837746,\n",
       "  0.4310226492793411,\n",
       "  0.40827922077922074],\n",
       " 'top2_ratios': [0.9969942196531792,\n",
       "  0.969251890431258,\n",
       "  0.995219068580024,\n",
       "  0.9973583320915237,\n",
       "  0.9941147001940108,\n",
       "  0.9779876224638323,\n",
       "  0.99629562097033,\n",
       "  0.9900649518762182,\n",
       "  0.9944890330714224,\n",
       "  0.9938608458390177,\n",
       "  0.9934423282431312,\n",
       "  0.9917007564148689,\n",
       "  0.9571443211859586,\n",
       "  0.998892147279244,\n",
       "  0.9848135525260626,\n",
       "  0.9535527340286933,\n",
       "  0.003984342560150042,\n",
       "  0.9943704578916456,\n",
       "  0.9766902637513483,\n",
       "  0.9725623445703234],\n",
       " 'new_sample_flags': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'avg_mem_rate': 0.4305087152475148,\n",
       " 'avg_top2_ratio': 0.9366394766811121,\n",
       " 'avg_new_sample_rate': 0.95}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_metrics = metric.calculate_memorization_metrics_batch(mts)\n",
    "mem_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26251af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44453125"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srs = metric.compute_srs(padded_latents_tensor, n_phrases)\n",
    "srs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "accgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

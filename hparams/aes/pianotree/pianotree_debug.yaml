# Example config for LightningCLI training VQVAE_Lightning
model:
  class_path: experiments.bar_compression.PianoTree_VAE
  init_args:
    max_simu_note: 16
    min_pitch: 0
    max_pitch: 127
    pitch_sos: 128
    pitch_eos: 129
    pitch_pad: 130
    dur_width: 6
    note_emb_size: 128
    enc_notes_hid_size: 256
    enc_time_hid_size: 512
    z_size: 512
    dec_emb_hid_size: 128
    dec_time_hid_size: 1024
    dec_notes_hid_size: 512
    dec_z_in_size: 256
    dec_dur_hid_size: 16
    num_step: 48
    lr: 0.001

data:
  class_path: datasets.pop909_dataset.POP909DataModule
  init_args:
    jsonl_fp: /data1/longshen/Datasets/Piano/POP909/jsonl/pop909_piano_track_bars.jsonl
    batch_size: 128
    num_workers: 4
    pin_memory: true
    val_split: 0.1


trainer:
  logger:
    class_path: pytorch_lightning.loggers.tensorboard.TensorBoardLogger
    init_args:
      save_dir: /data1/longshen/Results/AccGenResults/bar_compression/pianotree_vae_debug
      name: tb_logs
      default_hp_metric: false
  max_epochs: 20
  accelerator: gpu
  devices: -1
  log_every_n_steps: 10
  precision: 32
  default_root_dir: /data1/longshen/Results/AccGenResults/bar_compression/pianotree_vae_debug
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    - class_path: pytorch_lightning.callbacks.ModelSummary
      init_args:
        max_depth: 2
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        monitor: val_loss
        mode: min
        filename: '{epoch}_{step}_{val_loss:.4f}'
        save_top_k: 3
        save_last: true



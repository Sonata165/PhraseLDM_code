# S2SVQAE bar-level compression config

model:
  class_path: experiments.autoencoders.lit_vae.LitPhraseVAE
  init_args:
    t5_model_name: /data1/longshen/Results/AccGenResults/aes/pretrained/ae/epoch=129_step=69420_val_loss=0.0077.ckpt
    lit_ckpt: True
    tokenizer_path: LongshenOu/phrase-vae-tokenizer
    kld_weight: 0.01
    t5_config: 
      d_model: 512
      d_ff: 1024
      num_layers: 3
      num_heads: 6
      vocab_size: 1000
      decoder_start_token_id: 1
    compress_style: first_n_tokens  # first_token, full_sequence, pooling, first_n_tokens
    n_compress_tokens: 4
    bottleneck_dim: 512
    lr: 1e-4

data:
  class_path: datasets.pop909_dataset.POP909DataModule
  init_args:
    jsonl_fp_train: /data1/longshen/Datasets/Piano/POP909/jsonl/bar_level/train.jsonl
    jsonl_fp_val: /data1/longshen/Datasets/Piano/POP909/jsonl/bar_level/val.jsonl
    batch_size: 128
    num_workers: 4
    pin_memory: true
    val_split: 0.1
    dataset_class: POP909Dataset
    dataset_kwargs:
      tokenizer_path: LongshenOu/phrase-vae-tokenizer
      max_length: 128
      n_query_tokens: 4

trainer:
  logger:
    class_path: pytorch_lightning.loggers.tensorboard.TensorBoardLogger
    init_args:
      save_dir: /data1/longshen/Results/AccGenResults/aes/bar_level/pop909_phrase_flatten/s2s/mqcomp_vae_bottleneck/aeft_lr1e-4_klw0.01_b512_nokl
      name: tb_logs
      default_hp_metric: false
  max_epochs: 1000
  accelerator: gpu
  devices: -1
  log_every_n_steps: 10
  precision: 32
  default_root_dir: /data1/longshen/Results/AccGenResults/aes/bar_level/pop909_phrase_flatten/s2s/mqcomp_vae_bottleneck/aeft_lr1e-4_klw0.01_b512_nokl
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    - class_path: pytorch_lightning.callbacks.ModelSummary
      init_args:
        max_depth: 2
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        monitor: val_loss
        mode: min
        filename: '{epoch}_{step}_{val_loss:.4f}'
        save_top_k: 3
        save_last: true
    - class_path: pytorch_lightning.callbacks.EarlyStopping
      init_args:
        monitor: val_loss
        mode: min
        patience: 20
        verbose: true
